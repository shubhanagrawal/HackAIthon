{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing real videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:07<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fake videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:48<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes: Train - (280, 10, 128, 128, 3), Validation - (60, 10, 128, 128, 3), Test - (60, 10, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "# Dataset paths\n",
    "REAL_PATH = r'D:\\Hackathon_datasets\\FF++\\real'  # Corrected path\n",
    "FAKE_PATH = r'D:\\Hackathon_datasets\\FF++\\fake'\n",
    "OUTPUT_FRAME_SIZE = (128, 128)  # Frame dimensions\n",
    "FRAME_COUNT = 10  # Number of frames to extract per video\n",
    "MAX_VIDEOS = 700  # Number of videos to process from each category\n",
    "\n",
    "# Function to extract frames from a video\n",
    "def extract_frames(video_path, output_size=(128, 128), frame_count=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(total_frames // frame_count, 1)  # Uniform sampling\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, output_size)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Prepare data and labels\n",
    "data = []\n",
    "labels=[]\n",
    "# Process real videos\n",
    "print(\"Processing real videos...\")\n",
    "real_videos = os.listdir(REAL_PATH)[:MAX_VIDEOS]   # Limit to 300 videos\n",
    "for video_file in tqdm(real_videos):\n",
    "    video_path = os.path.join(REAL_PATH, video_file)\n",
    "    frames = extract_frames(video_path, output_size=OUTPUT_FRAME_SIZE, frame_count=FRAME_COUNT)\n",
    "    if len(frames) == FRAME_COUNT:  # Ensure correct frame count\n",
    "        data.append(frames)\n",
    "        labels.append(0)  # Label 0 for real\n",
    "\n",
    "      # Process fake videos\n",
    "print(\"Processing fake videos...\")\n",
    "fake_videos = os.listdir(FAKE_PATH)[:MAX_VIDEOS]  # Limit to 300 videos\n",
    "for video_file in tqdm(fake_videos):\n",
    "    video_path = os.path.join(FAKE_PATH, video_file)\n",
    "    frames = extract_frames(video_path, output_size=OUTPUT_FRAME_SIZE, frame_count=FRAME_COUNT)\n",
    "    if len(frames) == FRAME_COUNT:\n",
    "        data.append(frames)\n",
    "        labels.append(1)  # Label 1 for fake\n",
    "\n",
    "      # Convert to numpy arrays\n",
    "data = np.array(data)  # Shape: (num_videos, num_frames, 128, 128, 3)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "print(f\"Data shapes: Train - {X_train.shape}, Validation - {X_val.shape}, Test - {X_test.shape}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
